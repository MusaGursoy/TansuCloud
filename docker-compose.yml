services:
  postgres:
    image: tansu/citus-pgvector:local
    container_name: tansu-postgres
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - tansu-pgdata:/var/lib/postgresql/data
      - ./dev/db-init:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432" # Host exposure for EfMigrationsIntegrationTests
    networks:
      - tansucloud-network

  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: signoz-zookeeper
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      - ZOO_SERVER_ID=1
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOO_AUTOPURGE_INTERVAL=1
      - ZOO_ENABLE_PROMETHEUS_METRICS=yes
      - ZOO_4LW_COMMANDS_WHITELIST=ruok
    healthcheck:
      # Use AdminServer HTTP endpoint for health probing to avoid 4lw TCP restrictions
      test: ["CMD", "/bin/bash", "-lc", "wget -q -O - http://127.0.0.1:8080/commands/ruok | grep imok"]
      interval: 30s
      timeout: 5s
      retries: 5
    volumes:
      - signoz-zookeeper-data:/bitnami/zookeeper
    networks:
      - tansucloud-network

  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: signoz-clickhouse
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      CLICKHOUSE_DB: signoz
      CLICKHOUSE_USER: admin
      CLICKHOUSE_PASSWORD: admin
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "0.0.0.0:8123/ping"]
      interval: 30s
      timeout: 5s
      retries: 5
    volumes:
      - signoz-clickhouse-data:/var/lib/clickhouse
      - ./dev/clickhouse/cluster.xml:/etc/clickhouse-server/config.d/cluster.xml:ro
      - ./dev/clickhouse/zookeeper.xml:/etc/clickhouse-server/config.d/zookeeper.xml:ro
    ports:
      - "8123:8123" # Expose ClickHouse HTTP interface for E2E tests; host port fixed to 8123 for local tooling compatibility
    depends_on:
      - zookeeper
    networks:
      - tansucloud-network

  # SigNoz UI / query service (exposes the web UI)
  signoz:
    image: signoz/signoz:latest
    container_name: signoz
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      - SIGNOZ_TELEMETRYSTORE_PROVIDER=clickhouse
      - SIGNOZ_TELEMETRYSTORE_CLICKHOUSE_DSN=tcp://admin:admin@clickhouse:9000
      # Enable distributed tables on the single-node cluster named "cluster"
      - SIGNOZ_TELEMETRYSTORE_CLICKHOUSE_CLUSTER=cluster
      - SIGNOZ_ALERTMANAGER_PROVIDER=signoz
      - SIGNOZ_JWT_SECRET=dev-signoz-jwt-secret-change-me
    user: "0:0"
    # NOTE: SigNoz listens on 8080 internally. To avoid clashing with our Gateway's host mapping,
    # we publish it on host port 3301 while keeping the container default port. Access: http://127.0.0.1:3301/
    ports:
      - "3301:8080"
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/"]
      interval: 30s
      timeout: 5s
      retries: 10
    depends_on:
      - clickhouse
    networks:
      - tansucloud-network
    volumes:
      - signoz-data:/var/lib/signoz

  # SigNoz OpenTelemetry collector (receives OTLP from all services)
  signoz-otel-collector:
    image: signoz/signoz-otel-collector:latest
    container_name: signoz-otel-collector
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    command:
      - --config=/etc/otel-collector-config.yaml
    environment:
      - OTEL_RESOURCE_ATTRIBUTES=host.name=signoz-host,os.type=linux
      - LOW_CARDINAL_EXCEPTION_GROUPING=false
    # Expose OTLP endpoints to the host for local tests and readiness checks
    ports:
      - "4317:4317" # OTLP gRPC
      - "4318:4318" # OTLP HTTP
    volumes:
      - ./dev/signoz-otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    depends_on:
      - signoz
      - schema-migrator-sync
    networks:
      - tansucloud-network

  # SigNoz ClickHouse schema migrators (create/update signoz_* databases)
  schema-migrator-sync:
    image: signoz/signoz-schema-migrator:latest
    container_name: signoz-schema-migrator-sync
    # In single-node dev, run all migrations once and exit successfully.
    # Avoid --dev to prevent skipping squashed migrations in local runs.
    command: ["sync", "--dsn=tcp://admin:admin@clickhouse:9000"]
    restart: on-failure
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      # Ensure migrator creates distributed_* objects using the same cluster name
      - SIGNOZ_TELEMETRYSTORE_CLICKHOUSE_CLUSTER=cluster
    depends_on:
      clickhouse:
        condition: service_healthy
      clickhouse-prepatch:
        condition: service_completed_successfully
      clickhouse-compat-init:
        condition: service_completed_successfully
    networks:
      - tansucloud-network

  schema-migrator-async:
    image: signoz/signoz-schema-migrator:latest
    container_name: signoz-schema-migrator-async
    # Background worker; in dev, it can stay running, but should not crash-loop.
    # Avoid --dev to prevent skipping squashed migrations in local runs.
    command: ["async", "--dsn=tcp://admin:admin@clickhouse:9000"]
    restart: on-failure
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      # Ensure migrator creates distributed_* objects using the same cluster name
      - SIGNOZ_TELEMETRYSTORE_CLICKHOUSE_CLUSTER=cluster
    depends_on:
      clickhouse:
        condition: service_healthy
      schema-migrator-sync:
        condition: service_completed_successfully
    networks:
      - tansucloud-network

  # Dev-only prepatch job to create minimal tables/views required by migrator and collector
  clickhouse-prepatch:
    image: clickhouse/clickhouse-server:latest
    container_name: signoz-clickhouse-prepatch
    restart: on-failure
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
    depends_on:
      clickhouse:
        condition: service_healthy
    networks:
      - tansucloud-network
    entrypoint: ["bash","-lc"]
    volumes:
      - ./dev/clickhouse/prepatches:/prepatches:ro
    command:
      - >-
        bash /prepatches/run-prepatches.sh

  # Dev-only compatibility init for SigNoz traces API
  # Ensures the view signoz_traces.distributed_top_level_operations exists, which
  # some SigNoz query paths rely on for the Services page. Idempotent and safe.
  clickhouse-compat-init:
    image: clickhouse/clickhouse-client:latest
    container_name: signoz-clickhouse-compat-init
    restart: on-failure
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    depends_on:
      clickhouse:
        condition: service_healthy
      clickhouse-prepatch:
        condition: service_completed_successfully
    networks:
      - tansucloud-network
    entrypoint: ["bash","-c"]
    volumes:
      - ./dev/clickhouse/patches:/patches:ro
    command: |
      set -euo pipefail
      clickhouse-client --host clickhouse --port 9000 --user admin --password admin -q "CREATE MATERIALIZED VIEW IF NOT EXISTS signoz_traces.root_operations ON CLUSTER cluster AS SELECT DISTINCT name, resource_string_service\$\$name AS serviceName FROM signoz_traces.signoz_index_v3 WHERE parent_span_id = ''"
      clickhouse-client --host clickhouse --port 9000 --user admin --password admin -q "CREATE MATERIALIZED VIEW IF NOT EXISTS signoz_traces.distributed_top_level_operations ON CLUSTER cluster AS SELECT name, serviceName, toDateTime(timestamp) AS time FROM signoz_traces.distributed_signoz_index_v3 WHERE parent_span_id = '' OR length(parent_span_id) = 0"
      for f in /patches/*.sql; do echo "Applying patch: $f"; clickhouse-client --host clickhouse --port 9000 --user admin --password admin -n < "$f"; done

  redis:
    image: redis:latest
    container_name: tansu-redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    command: ["redis-server", "--appendonly", "yes"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 10
      start_period: 5s
    volumes:
      - tansu-redisdata:/data
    networks:
      - tansucloud-network

  pgcat:
    image: ghcr.io/postgresml/pgcat:latest
    container_name: tansu-pgcat
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      PGCAT_ADMIN_USER: ${PGCAT_ADMIN_USER}
      PGCAT_ADMIN_PASSWORD: ${PGCAT_ADMIN_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST: postgres
    volumes:
      - ./dev/pgcat/pgcat.toml:/etc/pgcat/pgcat.toml:ro
    command: ["pgcat", "/etc/pgcat/pgcat.toml"]
    expose:
      - "6432"
      - "9930"
    healthcheck:
      # Check that the pgcat process is running (avoid relying on pgrep availability)
      test: ["CMD-SHELL", "cat /proc/1/cmdline | tr '\\0' ' ' | grep -qi pgcat"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 20s
    networks:
      - tansucloud-network

  pgcat-config:
    build:
      context: .
      dockerfile: Dev.PgcatConfigurator/Dockerfile
    container_name: tansu-pgcat-config
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      PG_ADMIN: "Host=postgres;Port=5432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      PG_HOST: postgres
      PG_USER: ${POSTGRES_USER}
      PG_PASSWORD: ${POSTGRES_PASSWORD}
      TENANT_DB_PREFIX: tansu_tenant_
      PGCAT_ADMIN_USER: ${PGCAT_ADMIN_USER}
      PGCAT_ADMIN_PASSWORD: ${PGCAT_ADMIN_PASSWORD}
      PGCAT_CONFIG: /out/pgcat.toml
    volumes:
      - ./dev/pgcat:/out
    networks:
      - tansucloud-network
    depends_on:
      - pgcat

  identity:
    build:
      context: .
      dockerfile: TansuCloud.Identity/Dockerfile
    container_name: tansu-identity
    restart: unless-stopped
    ports:
      - "5095:8080"
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      PublicBaseUrl: ${PUBLIC_BASE_URL}
      GatewayBaseUrl: ${GATEWAY_BASE_URL}
      # Important in dev: advertise browser-visible endpoints from discovery
      # so redirects use 127.0.0.1 instead of the in-cluster name "gateway".
      Oidc__Issuer: ${PUBLIC_BASE_URL}/identity/
      Oidc__RedirectUri: ${PUBLIC_BASE_URL}/dashboard/signin-oidc
      Oidc__PostLogoutRedirectUri: ${PUBLIC_BASE_URL}/dashboard/signout-callback-oidc
      Oidc__Dashboard__RedirectUri: ${PUBLIC_BASE_URL}/dashboard/signin-oidc
      Oidc__Dashboard__RedirectUriRoot: ${PUBLIC_BASE_URL}/signin-oidc
      Oidc__Dashboard__ClientSecret: ${DASHBOARD_CLIENT_SECRET:-dev-secret}
      Oidc__Dashboard__PostLogoutRedirectUri: ${PUBLIC_BASE_URL}/dashboard/signout-callback-oidc
      Oidc__Dashboard__PostLogoutRedirectUriRoot: ${PUBLIC_BASE_URL}/signout-callback-oidc
      OpenTelemetry__Otlp__Endpoint: http://signoz-otel-collector:4317
      ConnectionStrings__Default: "Host=pgcat;Port=6432;Database=tansu_identity;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      Cache__Redis: redis:6379
      Audit__ConnectionString: "Host=pgcat;Port=6432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    networks:
      - tansucloud-network
    depends_on:
      pgcat:
        condition: service_healthy

  dashboard:
    build:
      context: .
      dockerfile: TansuCloud.Dashboard/Dockerfile
    user: "0:0"
    container_name: tansu-dashboard
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      PublicBaseUrl: ${PUBLIC_BASE_URL}
      OpenTelemetry__Otlp__Endpoint: http://signoz-otel-collector:4317
      Cache__Redis: redis:6379
      # Route audit writes via PgCat; avoid localhost inside container
      Audit__ConnectionString: "Host=pgcat;Port=6432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      Oidc__Authority: ${PUBLIC_BASE_URL}/identity
      # Use in-cluster gateway for backchannel discovery; browser-facing Authority follows PUBLIC_BASE_URL
      Oidc__MetadataAddress: ${GATEWAY_BASE_URL}/identity/.well-known/openid-configuration
      Oidc__RequireHttpsMetadata: false
      Oidc__ClientId: tansu-dashboard
      Oidc__ClientSecret: ${DASHBOARD_CLIENT_SECRET:-dev-secret}
      # Dev-only: bypass id_token signature to isolate env/test issues; disable in production
      DASHBOARD_BYPASS_IDTOKEN_SIGNATURE: "1"
      GatewayBaseUrl: ${GATEWAY_BASE_URL}
      # Dev convenience: standard ClickHouse HTTP for host tooling and docs. Avoids .env edits.
      # Note: this is primarily for humans/tools; app containers do not read this variable.
      CLICKHOUSE_HTTP: http://127.0.0.1:8123
      # Prometheus has been removed in favor of SigNoz. Leave unset to disable legacy metrics proxy.
      # Prometheus__BaseUrl: 
      LogReporting__Enabled: ${LOGREPORTING__ENABLED:-true}
      LogReporting__MainServerUrl: ${LOGREPORTING__MAINSERVERURL:-http://telemetry:8080/api/logs/report}
      LogReporting__ApiKey: ${LOGREPORTING__APIKEY:-dev-telemetry-api-key-1234567890}
      LogReporting__ReportIntervalMinutes: ${LOGREPORTING__REPORTINTERVALMINUTES:-60}
      LogReporting__TenantHashSecret: ${LOGREPORTING__TENANTHASHSECRET:-}
      LogReporting__PseudonymizeTenants: ${LOGREPORTING__PSEUDONYMIZETENANTS:-true}
    volumes:
      - tansu-dashboard-keys:/keys
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    networks:
      - tansucloud-network

  db:
    build:
      context: .
      dockerfile: TansuCloud.Database/Dockerfile
    container_name: tansu-db
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      PublicBaseUrl: ${PUBLIC_BASE_URL}
      GatewayBaseUrl: ${GATEWAY_BASE_URL}
      Oidc__Issuer: ${PUBLIC_BASE_URL}/identity/
      Oidc__MetadataAddress: ${GATEWAY_BASE_URL}/identity/.well-known/openid-configuration
      OpenTelemetry__Otlp__Endpoint: http://signoz-otel-collector:4317
      Outbox__RedisConnection: redis:6379
      Outbox__Channel: tansu.outbox
      Outbox__PollSeconds: 2
      Outbox__BatchSize: 100
      Outbox__MaxAttempts: 8
      Outbox__DispatchTenant: acme-dev
      Cache__Redis: redis:6379
      Provisioning__AdminConnectionString: "Host=postgres;Port=5432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      Provisioning__RuntimeConnectionString: "Host=pgcat;Port=6432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      Dev__ProvisionBypassKey: letmein
      Audit__ConnectionString: "Host=pgcat;Port=6432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    networks:
      - tansucloud-network
    depends_on:
      pgcat:
        condition: service_healthy
      redis:
        condition: service_healthy

  storage:
    build:
      context: .
      dockerfile: TansuCloud.Storage/Dockerfile
    user: "0:0"
    container_name: tansu-storage
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      STORAGE_ENABLE_TEST_THROW: "1" # Enable dev-only /dev/throw endpoint for E2E
      PublicBaseUrl: ${PUBLIC_BASE_URL}
      GatewayBaseUrl: ${GATEWAY_BASE_URL}
      Oidc__Issuer: ${PUBLIC_BASE_URL}/identity/
      Oidc__MetadataAddress: ${GATEWAY_BASE_URL}/identity/.well-known/openid-configuration
      OpenTelemetry__Otlp__Endpoint: http://signoz-otel-collector:4317
      Cache__Redis: redis:6379
      # Use a writable path for filesystem-backed storage inside the container
      Storage__RootPath: /data
      # Dev-only presign secret to enable presigned URL validation in E2E
      Storage__PresignSecret: dev-presign
      # Enforce a max per-part size for multipart uploads (1 MiB) to validate E2E behavior
      Storage__MultipartMaxPartSizeBytes: 1048576
      Audit__ConnectionString: "Host=pgcat;Port=6432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    networks:
      - tansucloud-network
    volumes:
      - tansu-storagedata:/data
    depends_on:
      redis:
        condition: service_healthy

  telemetry:
    build:
      context: .
      dockerfile: TansuCloud.Telemetry/Dockerfile
    container_name: tansu-telemetry
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      OpenTelemetry__Otlp__Endpoint: http://signoz-otel-collector:4317
      Telemetry__Ingestion__ApiKey: "${TELEMETRY__INGESTION__APIKEY:-dev-telemetry-api-key-1234567890}"
      Telemetry__Admin__ApiKey: "${TELEMETRY__ADMIN__APIKEY:-dev-telemetry-admin-key-9876543210}"
      Telemetry__Database__FilePath: /var/opt/tansu/telemetry/telemetry.db
      Telemetry__Database__EnforceForeignKeys: true
    volumes:
      - tansu-telemetrydata:/var/opt/tansu/telemetry
    ports:
      - "5279:8080"
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    depends_on:
      signoz-otel-collector:
        condition: service_started
    networks:
      - tansucloud-network

  gateway:
    build:
      context: .
      dockerfile: TansuCloud.Gateway/Dockerfile
    container_name: tansu-gateway
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      PublicBaseUrl: ${PUBLIC_BASE_URL}
      GatewayBaseUrl: ${GATEWAY_BASE_URL}
      GATEWAY_URLS: http://0.0.0.0:8080
      Kestrel__Endpoints__Http__Url: http://0.0.0.0:8080
      Services__DashboardBaseUrl: http://dashboard:8080
      Services__IdentityBaseUrl: http://identity:8080
      Services__DatabaseBaseUrl: http://db:8080
      Services__StorageBaseUrl: http://storage:8080
      OpenTelemetry__Otlp__Endpoint: http://signoz-otel-collector:4317
      Cache__Redis: redis:6379
      Dev__ProvisionBypassKey: letmein
      Audit__ConnectionString: "Host=pgcat;Port=6432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
    ports:
      - "80:8080"
      - "8080:8080"
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    depends_on:
      postgres:
        condition: service_started
      identity:
        condition: service_healthy
      dashboard:
        condition: service_healthy
      db:
        condition: service_healthy
      storage:
        condition: service_healthy
      signoz-otel-collector:
        condition: service_started
    networks:
      - tansucloud-network

networks:
  tansucloud-network:
    driver: bridge

volumes:
  tansu-pgdata:
    driver: local
  tansu-redisdata:
    driver: local
  tansu-storagedata:
    driver: local
  tansu-dashboard-keys:
    driver: local
  signoz-clickhouse-data:
    driver: local
  signoz-zookeeper-data:
    driver: local
  signoz-data:
    driver: local
  tansu-telemetrydata:
    driver: local
