# Development: Uses :latest for fast iteration
# Production: Pin specific versions to prevent surprise upgrades

services:
  postgres:
    build:
      context: .
      dockerfile: dev/Dockerfile.citus-pgvector
    image: tansu/citus-pgvector:local
    container_name: tansu-postgres
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - tansu-pgdata:/var/lib/postgresql/data
      # Init scripts (01-init.sql) are baked into the Docker image (see dev/Dockerfile.citus-pgvector)
      # No bind mount needed - databases are created automatically on first start
      # - ./dev/db-init:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"  # Exposed for host-based E2E tests
    # Access: Tests run on host and access via localhost:5432
    # Debugging: docker exec -it tansu-postgres psql -U postgres
    networks:
      - tansucloud-network

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: tansu-postgres-exporter
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/postgres?sslmode=disable"
    expose:
      - "9187"
    depends_on:
      postgres:
        condition: service_started
    networks:
      - tansucloud-network

  # ========================================
  # PGTL Stack - Phase 1: Prometheus Metrics
  # ========================================
  
  # OpenTelemetry Collector - Routes telemetry to PGTL stack
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.114.0
    container_name: tansu-otel-collector
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./dev/otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    # NOTE: OTLP ports NOT exposed to host (security + production parity)
    # Access: Services in Docker network use otel-collector:4317
    # Debugging: docker logs tansu-otel-collector --tail 50
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:13133/"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      prometheus:
        condition: service_started
    networks:
      - tansucloud-network
  
  prometheus:
    image: prom/prometheus:v3.0.1
    container_name: tansu-prometheus
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-remote-write-receiver'
    volumes:
      - ./dev/prometheus-config.yml:/etc/prometheus/prometheus.yml:ro
      - tansu-prometheus-data:/prometheus
    # NOTE: Prometheus is accessible only within the Docker network via http://prometheus:9090
    # All observability access goes through the Dashboard API - no direct external port exposure
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - tansucloud-network

  tempo:
    image: grafana/tempo:2.6.0
    container_name: tansu-tempo
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
    command:
      - '-config.file=/etc/tempo.yml'
    volumes:
      - ./dev/tempo-config.yml:/etc/tempo.yml:ro
      - tansu-tempo-data:/var/tempo
    # NOTE: Tempo is accessible only within the Docker network via http://tempo:3200
    # Traces accessed through Dashboard API - no direct external port exposure
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3200/ready"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - tansucloud-network

  loki:
    image: grafana/loki:3.3.1
    container_name: tansu-loki
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
    command:
      - '-config.file=/etc/loki.yml'
    volumes:
      - ./dev/loki-config.yml:/etc/loki.yml:ro
      - tansu-loki-data:/loki
    # NOTE: Loki is accessible only within the Docker network via http://loki:3100
    # Logs accessed through Dashboard API - no direct external port exposure
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - tansucloud-network

  grafana:
    image: grafana/grafana:latest
    container_name: tansu-grafana
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
    environment:
      # Database (PostgreSQL backend)
      GF_DATABASE_TYPE: postgres
      GF_DATABASE_HOST: postgres:5432
      GF_DATABASE_NAME: grafana
      GF_DATABASE_USER: ${POSTGRES_USER}
      GF_DATABASE_PASSWORD: ${POSTGRES_PASSWORD}
      # Security
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_AUTH_DISABLE_LOGIN_FORM: "false"
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: Viewer
      # Server (internal address; Gateway handles proxy via X-Forwarded-Prefix)
      GF_SERVER_ROOT_URL: ${PUBLIC_BASE_URL}/grafana
      GF_SERVER_SERVE_FROM_SUB_PATH: "true"
      GF_SERVER_HTTP_PORT: "3000"
      # Security - Allow embedding in iframe (dev only, Dashboard embeds Grafana dashboards)
      GF_SECURITY_ALLOW_EMBEDDING: "true"
      # Disable telemetry
      GF_ANALYTICS_REPORTING_ENABLED: "false"
      GF_ANALYTICS_CHECK_FOR_UPDATES: "false"
    volumes:
      - ./dev/grafana/provisioning:/etc/grafana/provisioning:ro
      - tansu-grafana-data:/var/lib/grafana
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    depends_on:
      postgres:
        condition: service_started
      prometheus:
        condition: service_healthy
      tempo:
        condition: service_healthy
      loki:
        condition: service_healthy
    networks:
      - tansucloud-network
    # NOTE: Grafana is accessible only within Docker network
    # Access via Gateway /grafana/* route (optional, disabled by default)
    # Or embed dashboards in Admin Dashboard via iframe

  redis:
    image: ghcr.io/microsoft/garnet:latest
    container_name: tansu-redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    command: ["/app/GarnetServer", "--port", "6379", "--checkpointdir", "/data", "--recover"]
    ports:
      - "6379:6379"  # Exposed for host-based E2E tests
    # Access: Tests run on host and access via localhost:6379
    # Debugging: docker exec -it tansu-redis /app/GarnetServer --test-ping
    healthcheck:
      test: ["CMD", "/app/GarnetServer", "--test-ping"]
      interval: 10s
      timeout: 3s
      retries: 10
      start_period: 5s
    volumes:
      - tansu-garnetdata:/data
    networks:
      - tansucloud-network

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: tansu-redis-exporter
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
    environment:
      REDIS_ADDR: redis:6379
    expose:
      - "9121"
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - tansucloud-network

  pgcat:
    image: ghcr.io/postgresml/pgcat:latest
    container_name: tansu-pgcat
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      PGCAT_ADMIN_USER: ${PGCAT_ADMIN_USER}
      PGCAT_ADMIN_PASSWORD: ${PGCAT_ADMIN_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST: postgres
    volumes:
      - ./dev/pgcat/pgcat.toml:/etc/pgcat/pgcat.toml:ro
    command: ["pgcat", "/etc/pgcat/pgcat.toml"]
    expose:
      - "6432"
      - "9930" # Admin API port
    healthcheck:
      # Check that the pgcat process is running (avoid relying on pgrep availability)
      test: ["CMD-SHELL", "cat /proc/1/cmdline | tr '\\0' ' ' | grep -qi pgcat"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 20s
    networks:
      - tansucloud-network

  identity:
    build:
      context: .
      dockerfile: TansuCloud.Identity/Dockerfile
    container_name: tansu-identity
    restart: unless-stopped
    # NOTE: Port NOT exposed to host - all access via Gateway /identity/
    # Production parity: Identity never directly exposed
    # Debugging: docker logs tansu-identity --tail 50
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      PublicBaseUrl: ${PUBLIC_BASE_URL}
      GatewayBaseUrl: ${GATEWAY_BASE_URL}
      # Important in dev: advertise browser-visible endpoints from discovery
      # so redirects use 127.0.0.1 instead of the in-cluster name "gateway".
      Oidc__Issuer: ${PUBLIC_BASE_URL}/identity/
      Oidc__RedirectUri: ${PUBLIC_BASE_URL}/dashboard/signin-oidc
      Oidc__PostLogoutRedirectUri: ${PUBLIC_BASE_URL}/dashboard/signout-callback-oidc
      Oidc__Dashboard__RedirectUri: ${PUBLIC_BASE_URL}/dashboard/signin-oidc
      Oidc__Dashboard__RedirectUriRoot: ${PUBLIC_BASE_URL}/signin-oidc
      Oidc__Dashboard__ClientSecret: ${DASHBOARD_CLIENT_SECRET:-dev-secret}
      Oidc__Dashboard__PostLogoutRedirectUri: ${PUBLIC_BASE_URL}/dashboard/signout-callback-oidc
      Oidc__Dashboard__PostLogoutRedirectUriRoot: ${PUBLIC_BASE_URL}/signout-callback-oidc
      OpenTelemetry__Otlp__Enabled: true
      OpenTelemetry__Otlp__Endpoint: http://otel-collector:4317
      ConnectionStrings__Default: "Host=pgcat;Port=6432;Database=tansu_identity;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      Cache__Redis: redis:6379
      Audit__ConnectionString: "Host=pgcat;Port=6432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    networks:
      - tansucloud-network
    depends_on:
      pgcat:
        condition: service_healthy
      db:
        condition: service_healthy

  dashboard:
    build:
      context: .
      dockerfile: TansuCloud.Dashboard/Dockerfile
    user: "0:0"
    container_name: tansu-dashboard
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      PublicBaseUrl: ${PUBLIC_BASE_URL}
      OpenTelemetry__Otlp__Enabled: true
      OpenTelemetry__Otlp__Endpoint: http://otel-collector:4317
      Cache__Redis: redis:6379
      # Route audit writes via PgCat; avoid localhost inside container
      Audit__ConnectionString: "Host=pgcat;Port=6432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      # Prometheus Query Service API (Task 47 Phase 1 - Prometheus metrics)
      PrometheusQuery__ApiBaseUrl: http://prometheus:9090
      PrometheusQuery__PrometheusUiBaseUrl: http://prometheus:9090
      PrometheusQuery__TimeoutSeconds: 30
      PrometheusQuery__MaxRetries: 2
      # Tempo Query Service API (Task 47 Phase 2 - Tempo traces)
      TempoQuery__ApiBaseUrl: http://tempo:3200
      TempoQuery__TimeoutSeconds: 30
      TempoQuery__MaxRetries: 2
      # Loki Query Service API (Task 47 Phase 3 - Loki logs)
      LokiQuery__ApiBaseUrl: http://loki:3100
      LokiQuery__TimeoutSeconds: 30
      LokiQuery__MaxRetries: 2
      # Grafana Dashboard Embedding (Task 47 Phase 4 - Grafana visualization)
      Grafana__Enabled: ${GRAFANA_ENABLED:-true}
      Grafana__BaseUrl: ${PUBLIC_BASE_URL}/grafana
      Oidc__Authority: ${PUBLIC_BASE_URL}/identity
      # Use gateway for backchannel discovery (containers can't reach 127.0.0.1)
      # Gateway now passes through Identity's issuer unchanged
      Oidc__MetadataAddress: ${GATEWAY_BASE_URL}/identity/.well-known/openid-configuration
      Oidc__RequireHttpsMetadata: false
      Oidc__ClientId: tansu-dashboard
      Oidc__ClientSecret: ${DASHBOARD_CLIENT_SECRET:-dev-secret}
      # Dev-only: bypass id_token signature to isolate env/test issues; disable in production
      DASHBOARD_BYPASS_IDTOKEN_SIGNATURE: "1"
      GatewayBaseUrl: ${GATEWAY_BASE_URL}
      LogReporting__Enabled: ${LOGREPORTING__ENABLED:-true}
      LogReporting__MainServerUrl: ${LOGREPORTING__MAINSERVERURL:-http://telemetry:8080/api/logs/report}
      LogReporting__ApiKey: ${LOGREPORTING__APIKEY:-dev-telemetry-api-key-1234567890}
      LogReporting__ReportIntervalMinutes: ${LOGREPORTING__REPORTINTERVALMINUTES:-60}
      LogReporting__TenantHashSecret: ${LOGREPORTING__TENANTHASHSECRET:-}
      LogReporting__PseudonymizeTenants: ${LOGREPORTING__PSEUDONYMIZETENANTS:-true}
    volumes:
      - tansu-dashboard-keys:/keys
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    networks:
      - tansucloud-network

  db:
    build:
      context: .
      dockerfile: TansuCloud.Database/Dockerfile
    container_name: tansu-db
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      PublicBaseUrl: ${PUBLIC_BASE_URL}
      GatewayBaseUrl: ${GATEWAY_BASE_URL}
      Oidc__Issuer: ${PUBLIC_BASE_URL}/identity/
      Oidc__MetadataAddress: ${GATEWAY_BASE_URL}/identity/.well-known/openid-configuration
      OpenTelemetry__Otlp__Enabled: true
      OpenTelemetry__Otlp__Endpoint: http://otel-collector:4317
      Outbox__RedisConnection: redis:6379
      Outbox__Channel: tansu.outbox
      Outbox__PollSeconds: 2
      Outbox__BatchSize: 100
      Outbox__MaxAttempts: 8
      # Outbox__DispatchTenant: acme-dev  # Removed: tenant doesn't exist, outbox will dispatch per-request
      Cache__Redis: redis:6379
      ConnectionStrings__DefaultConnection: "Host=postgres;Port=5432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      Provisioning__AdminConnectionString: "Host=postgres;Port=5432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      # Temporarily use direct PostgreSQL instead of PgCat until dynamic pool management is implemented (Task 46)
      # PgCat HTTP Admin API does not exist - see docs/PgCat-Admin-API-Investigation.md
      Provisioning__RuntimeConnectionString: "Host=postgres;Port=5432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      Dev__ProvisionBypassKey: letmein
      Audit__ConnectionString: "Host=postgres;Port=5432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      # PgCat Admin API configuration (not currently used - HTTP API does not exist)
      PgCat__AdminBaseUrl: http://pgcat:9930
      PGCAT_ADMIN_USER: ${PGCAT_ADMIN_USER}
      PGCAT_ADMIN_PASSWORD: ${PGCAT_ADMIN_PASSWORD}
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 60s
    networks:
      - tansucloud-network
    depends_on:
      pgcat:
        condition: service_healthy
      redis:
        condition: service_healthy

  storage:
    build:
      context: .
      dockerfile: TansuCloud.Storage/Dockerfile
    user: "0:0"
    container_name: tansu-storage
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      STORAGE_ENABLE_TEST_THROW: "1" # Enable dev-only /dev/throw endpoint for E2E
      PublicBaseUrl: ${PUBLIC_BASE_URL}
      GatewayBaseUrl: ${GATEWAY_BASE_URL}
      Oidc__Issuer: ${PUBLIC_BASE_URL}/identity/
      Oidc__MetadataAddress: ${GATEWAY_BASE_URL}/identity/.well-known/openid-configuration
      OpenTelemetry__Otlp__Enabled: true
      OpenTelemetry__Otlp__Endpoint: http://otel-collector:4317
      Cache__Redis: redis:6379
      # Use a writable path for filesystem-backed storage inside the container
      Storage__RootPath: /data
      # Dev-only presign secret to enable presigned URL validation in E2E
      Storage__PresignSecret: dev-presign
      # Enforce a max per-part size for multipart uploads (1 MiB) to validate E2E behavior
      Storage__MultipartMaxPartSizeBytes: 1048576
      Audit__ConnectionString: "Host=pgcat;Port=6432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    networks:
      - tansucloud-network
    volumes:
      - tansu-storagedata:/data
    depends_on:
      redis:
        condition: service_healthy

  # ========================================
  # Telemetry Service - Development Only
  # ========================================
  # NOTE: This service is NOT part of production TansuCloud deployments.
  # Purpose: Telemetry runs on the MAIN SERVER (tansu.cloud) to collect
  #          product diagnostics from customer TansuCloud deployments.
  # 
  # Architecture:
  #   - Customer deployments: Dashboard → HTTPS → telemetry.tansu.cloud
  #   - Main server: Standalone telemetry service (separate infrastructure)
  #   - NOT part of tansucloud-network in production
  # 
  # Development use:
  #   - Included here for local testing of Dashboard log reporting (Task 37)
  #   - Simulates the main server telemetry endpoint locally
  #   - Dashboard sends reports to http://telemetry:8080/api/logs/report
  # 
  # Production deployment:
  #   - Remove this service from docker-compose.prod.yml
  #   - Deploy telemetry separately on main server infrastructure
  #   - Configure Dashboard LogReporting__MainServerUrl to point to
  #     the actual main server endpoint (e.g., https://telemetry.tansu.cloud)
  # ========================================
  telemetry:
    build:
      context: .
      dockerfile: TansuCloud.Telemetry/Dockerfile
    container_name: tansu-telemetry
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      OpenTelemetry__Otlp__Enabled: true
      OpenTelemetry__Otlp__Endpoint: http://otel-collector:4317
      Telemetry__Ingestion__ApiKey: "${TELEMETRY__INGESTION__APIKEY:-dev-telemetry-api-key-1234567890}"
      Telemetry__Admin__ApiKey: "${TELEMETRY__ADMIN__APIKEY:-dev-telemetry-admin-key-9876543210}"
      Telemetry__Database__FilePath: /var/opt/tansu/telemetry/telemetry.db
      Telemetry__Database__EnforceForeignKeys: true
    volumes:
      - tansu-telemetrydata:/var/opt/tansu/telemetry
    # NOTE: Port NOT exposed - telemetry simulated locally for Dashboard testing
    # In production, telemetry runs on separate main server (not in customer network)
    # Dev access: Tests use http://telemetry:8080 inside Docker network
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    depends_on:
      otel-collector:
        condition: service_started
    networks:
      - tansucloud-network  # Dev-only: for local testing

  gateway:
    build:
      context: .
      dockerfile: TansuCloud.Gateway/Dockerfile
    container_name: tansu-gateway
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    volumes:
      - tansu-gateway-keys:/keys
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      PublicBaseUrl: ${PUBLIC_BASE_URL}
      GatewayBaseUrl: ${GATEWAY_BASE_URL}
      GATEWAY_URLS: http://0.0.0.0:8080
      Kestrel__Endpoints__Http__Url: http://0.0.0.0:8080
      Services__DashboardBaseUrl: http://dashboard:8080
      Services__IdentityBaseUrl: http://identity:8080
      Services__DatabaseBaseUrl: http://db:8080
      Services__StorageBaseUrl: http://storage:8080
      OpenTelemetry__Otlp__Enabled: true
      OpenTelemetry__Otlp__Endpoint: http://otel-collector:4317
      Cache__Redis: redis:6379
      Gateway__TrustForwardedHeaders: "true"
      Dev__ProvisionBypassKey: letmein
      Audit__ConnectionString: "Host=pgcat;Port=6432;Database=postgres;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
      ConnectionStrings__GatewayDb: "Host=pgcat;Port=6432;Database=tansu_identity;Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD}"
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "/bin/busybox", "wget", "-q", "-O", "-", "http://localhost:8080/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 25s
    depends_on:
      postgres:
        condition: service_started
      identity:
        condition: service_healthy
      dashboard:
        condition: service_healthy
      db:
        condition: service_healthy
      storage:
        condition: service_healthy
      otel-collector:
        condition: service_started
    networks:
      - tansucloud-network

  # ========================================
  # E2E Tests - Containerized Testing
  # ========================================
  # Purpose: Run E2E tests inside Docker network to access internal services
  # Usage: docker compose --profile testing up --build e2e-tests
  # Filter: docker compose run --rm e2e-tests --filter "FullyQualifiedName~LokiLogsE2E"
  # ========================================
  e2e-tests:
    build:
      context: .
      dockerfile: tests/TansuCloud.E2E.Tests/Dockerfile
    container_name: tansu-e2e-tests
    environment:
      # Container detection
      DOTNET_RUNNING_IN_CONTAINER: "true"
      
      # Gateway and public URLs (use internal service name)
      GATEWAY_BASE_URL: http://gateway:8080
      PUBLIC_BASE_URL: http://gateway:8080
      
      # PGTL Stack (internal service names)
      PROMETHEUS_API_BASE_URL: http://prometheus:9090
      TEMPO_API_BASE_URL: http://tempo:3200
      LOKI_API_BASE_URL: http://loki:3100
      
      # Infrastructure (internal service names)
      OTEL_COLLECTOR_BASE_URL: http://otel-collector:4317
      TELEMETRY_BASE_URL: http://telemetry:8080
      
      # Database connection (for EF migration tests)
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      
      # Test configuration
      ASPNETCORE_ENVIRONMENT: Development
    depends_on:
      gateway:
        condition: service_healthy
      postgres:
        condition: service_started
      redis:
        condition: service_healthy
      prometheus:
        condition: service_healthy
      tempo:
        condition: service_healthy
      loki:
        condition: service_healthy
      otel-collector:
        condition: service_started
      telemetry:
        condition: service_healthy
    networks:
      - tansucloud-network
    profiles:
      - testing  # Only run when explicitly requested

networks:
  tansucloud-network:
    driver: bridge

volumes:
  tansu-pgdata:
    driver: local
  tansu-garnetdata:
    driver: local
  tansu-storagedata:
    driver: local
  tansu-gateway-keys:
    driver: local
  tansu-dashboard-keys:
    driver: local
  tansu-prometheus-data:
    driver: local
  tansu-tempo-data:
    driver: local
  tansu-loki-data:
    driver: local
  tansu-grafana-data:
    driver: local
  tansu-telemetrydata:
    driver: local
