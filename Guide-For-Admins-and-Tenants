# Tansu.Cloud Admin & Tenant Guide

## Overview

Tansu.Cloud is a modern backend-as-a-service (BaaS) platform built on .NET, providing identity, API gateway, dashboards, database and storage services, observability, and health management. This guide helps admins and tenant operators deploy, configure, and operate the platform.

## 1. Getting Started

- Architecture at a glance
- Core services and responsibilities
- Environments (dev, staging, production)

## 2. Prerequisites

- Docker and Docker Compose
- Certificates (PFX) for TLS
- DNS and firewall basics

## 3. Quickstart: Local Development

- Run all services with VS Code tasks (dev: up / dev: down)
- Running with Docker Compose (gateway only exposed)
- Health endpoints (/health/live and /health/ready)

## 4. Production Topology

- Gateway-only exposure (80/443)
- Internal service networking
- OpenTelemetry collector

### 4.1 Custom domain and secrets (.env)

Set your public base URL and sensitive values via a `.env` file next to `docker-compose.yml`. Docker Compose will auto-load it and substitute values into service environments.

1) Create `.env` with your domain and secrets

```env
# Public HTTPS base URL of your gateway (include scheme; no trailing slash)
PUBLIC_BASE_URL=https://your-domain

# Dashboard OIDC confidential client secret (used by the Dashboard to obtain tokens)
DASHBOARD_CLIENT_SECRET=replace-with-strong-secret

# Postgres and PgCat credentials used by the stack
POSTGRES_USER=postgres
POSTGRES_PASSWORD=change-me
PGCAT_ADMIN_USER=admin
PGCAT_ADMIN_PASSWORD=change-me

# If you enable TLS on the gateway (see section 5), set the PFX password
GATEWAY_CERT_PASSWORD=changeit
```

2) What these influence

- PUBLIC_BASE_URL configures all OIDC and callback URLs exposed externally:
	- Identity issuer: `${PUBLIC_BASE_URL}/identity/`
	- Dashboard OIDC authority: `${PUBLIC_BASE_URL}/identity`
	- Redirect URIs (dashboard behind gateway path):
		- `${PUBLIC_BASE_URL}/dashboard/signin-oidc`
		- `${PUBLIC_BASE_URL}/dashboard/signout-callback-oidc`
	- Root variants (if you front the dashboard at the domain root as an alternative):
		- `${PUBLIC_BASE_URL}/signin-oidc`
		- `${PUBLIC_BASE_URL}/signout-callback-oidc`
- DASHBOARD_CLIENT_SECRET is injected into the Dashboard container as its client secret.
- POSTGRES_* and PGCAT_* configure the database and PgCat admin access used by services.
- GATEWAY_CERT_PASSWORD is only required when HTTPS is enabled on the gateway with a PFX (see 5.x).

3) DNS and TLS

- Point your domain (A/AAAA) to the gateway host.
- Use a valid certificate (section 5) and set `PUBLIC_BASE_URL` to the HTTPS origin.
- After the first start, confirm discovery at `${PUBLIC_BASE_URL}/identity/.well-known/openid-configuration`.

## 5. Certificates & TLS

- Preparing a PFX certificate
- Mounting certs via Compose (volumes)
- Configuring Kestrel HTTPS in gateway (appsettings Kestrel:Endpoints)
- Setting GATEWAY_CERT_PASSWORD

### 5.1 Dev SSL (self‑signed)

Use the helper script to create a local, self‑signed PFX and wire it to the gateway:

1. Generate a dev certificate

- Script: `dev/make-dev-cert.ps1`
- Output: `./certs/gateway.pfx` (you’ll be prompted for a password)

1. Point the gateway to the PFX

- HTTPS is disabled by default. Enable it via Docker Compose by mounting the PFX, exposing 443, and setting Kestrel HTTPS endpoint via environment variables:

```yaml
services:
	gateway:
		ports:
			- "80:8080"
			- "443:8443"            # enable HTTPS (container listens on 8443)
		volumes:
			- ./certs:/certs:ro      # contains gateway.pfx
		environment:
			- Kestrel__Endpoints__Https__Url=https://0.0.0.0:8443
			- Kestrel__Endpoints__Https__Certificate__Path=/certs/gateway.pfx
			- GATEWAY_CERT_PASSWORD=${GATEWAY_CERT_PASSWORD}
```

1. Provide the password

- Set `GATEWAY_CERT_PASSWORD` via `.env` or shell; it’s read at startup and used as the PFX password. See 5.3 for examples.

1. Browse

- Start compose; navigate to `https://localhost` (trust the self‑signed cert in your browser if prompted).

### 5.2 Real SSL (public CA)

1. Obtain a PFX for your domain

- Include the full chain (intermediate CAs) and set a strong password.

1. Mount and configure

- Place the PFX where Docker can mount it (e.g., `./certs/mydomain.pfx`).
- Configure the HTTPS endpoint via environment variables. The password must be provided via `GATEWAY_CERT_PASSWORD` using a `.env` file or shell variable (see 5.3):

```yaml
services:
	gateway:
		ports:
			- "80:8080"
			- "443:8443"
		volumes:
			- ./certs:/certs:ro
		environment:
			- Kestrel__Endpoints__Https__Url=https://0.0.0.0:8443
			- Kestrel__Endpoints__Https__Certificate__Path=/certs/mydomain.pfx
			- GATEWAY_CERT_PASSWORD=${GATEWAY_CERT_PASSWORD}
```

- Or re-add the Https endpoint in appsettings to pin the URL; still provide the password via `GATEWAY_CERT_PASSWORD` only (see 5.3).

1. DNS and callbacks

- Point your DNS (A/AAAA) to the gateway host.
- Update OIDC redirect URIs and issuers to use your HTTPS host.

1. Hardening (recommended)

- Enable HSTS, fine‑tune CORS allowlists, and use secret stores for certificate passwords.

### 5.3 How to provide the certificate password

Provide the password only via the environment variable `GATEWAY_CERT_PASSWORD`. Do not store it in appsettings or source control.

Option A — .env file (recommended for local/dev)

1. Create a `.env` file next to `docker-compose.yml` with:

```env
GATEWAY_CERT_PASSWORD=changeit
```

1. Ensure your gateway service `environment` section contains:

```yaml
environment:
	- Kestrel__Endpoints__Https__Url=https://0.0.0.0:8443
	- Kestrel__Endpoints__Https__Certificate__Path=/certs/gateway.pfx
	- GATEWAY_CERT_PASSWORD=${GATEWAY_CERT_PASSWORD}
```

Docker Compose will automatically load `.env` and substitute the value.

Option B — Shell environment variable (one-off runs, CI/CD)

- Windows PowerShell

```powershell
$env:GATEWAY_CERT_PASSWORD = "changeit"
docker compose up -d
```

- Bash (Linux/macOS)

```bash
export GATEWAY_CERT_PASSWORD=changeit
docker compose up -d
```

Notes

- Don’t commit real passwords into source control. Use `.env` (ignored by default) or secret managers/CI secrets.
- For HTTP-only runs, leave 443 and TLS envs unset, and (in dev) you can set `Gateway:DisableHttpsRedirect=true` to prevent redirects.

## 6. Identity & Authentication

- Identity issuer and discovery under /identity
- Configuring OIDC issuer for downstream services (Oidc:Issuer)
- Dashboard OIDC authority configuration

Recommended settings

- In production, set `PUBLIC_BASE_URL` to your HTTPS origin in `.env`. The compose file maps this to:
	- Identity Issuer: `${PUBLIC_BASE_URL}/identity/`
	- Dashboard Authority/Metadata: `${PUBLIC_BASE_URL}/identity`
	- Dashboard Redirect URIs:
		- `${PUBLIC_BASE_URL}/dashboard/signin-oidc`
		- `${PUBLIC_BASE_URL}/dashboard/signout-callback-oidc`
	- Optional root variants for alternative routing:
		- `${PUBLIC_BASE_URL}/signin-oidc`
		- `${PUBLIC_BASE_URL}/signout-callback-oidc`
- Set the Dashboard confidential client secret via `DASHBOARD_CLIENT_SECRET` in `.env`.
- Ensure reverse proxy forwarding headers are correct at the gateway; Identity relies on them for issuer/redirects.

Scopes (summary)

- db.read — read access to Database APIs.
- db.write — write access to Database APIs.
- storage.read — read access to Storage APIs.
- storage.write — write access to Storage APIs.
- admin.full — development-only convenience scope implying all of the above.

Gateway login alias

- For convenience, the gateway exposes a login alias at `/login` that redirects to the Identity login UI under `/identity`. This helps operators and testers quickly reach the sign-in form.

## 7. Configuration & Secrets

- Configuration sources (appsettings, environment, user secrets)
- Sensitive values (client secrets, cert passwords)
- Example environment variables and key paths

## 8. Health & Monitoring

- Health endpoints and readiness gates
- OpenTelemetry signals (traces, metrics, logs)
- Collector endpoint and backends

### 8.1 Caching (HybridCache) overview

- Services use Microsoft.Extensions.Caching.Hybrid with Redis as the distributed backing store when configured.
- Development toggle `Cache:Disable=1` (per service) bypasses HybridCache entirely for troubleshooting.
- Redis connectivity is covered by custom health checks ("redis" tag) that ping the configured endpoint; readiness will report degraded when Redis is unreachable.
- Cache keys are tenant-scoped and versioned: `t:{tenant}:v{version}:{service}:{resource}:...`.
	- Database invalidates via outbox events (see Task 12).
	- Storage bumps a per-tenant version on PUT/DELETE to invalidate list/head entries.
- Metrics: the Storage service exposes counters via the `tansu.storage` meter:
	- `tansu_storage_cache_attempts_total`
	- `tansu_storage_cache_hits_total`
	- `tansu_storage_cache_misses_total`
	Each counter includes an `op` tag (list/head). Exporters can aggregate/graph these for hit ratio.

Troubleshooting tips

- To temporarily disable caching in Development, set `Cache:Disable=1` on the affected service (e.g., Storage) and restart it.
- Verify Redis availability: check `/health/ready` and service logs for the Redis ping health check. In Compose, ensure the `redis` service is up.
- If responses seem stale after writes, confirm that the tenant cache version increments (Storage) or that outbox events flow (Database).

## 9. Operations

- Rolling updates and restarts
- Log collection and troubleshooting
- Backup and restore considerations (DB/storage specifics TBD)

## 10. Security Hardening

- CORS at the gateway
- TLS everywhere and HSTS (optional)
- Rate limiting and body size limits at the gateway

### 10.1 Gateway caching and request limits

Output caching (gateway)

- Base policy varies by:
  - Host and path
  - Headers: `X-Tansu-Tenant`, `Accept`, `Accept-Encoding`
  - Selected query parameters depending on route
- Authorization-aware:
  - When an `Authorization` header is present (authenticated, per-route protected content), the gateway bypasses output caching (no-store) to avoid serving cached private responses.

Global rate limits

- Partitioned by route prefix and tenant to reduce cross-tenant interference.

Request body size limits (defaults)

- Storage service: 100 MB
- Database service: 10 MB
- Identity service: 2 MB
- Dashboard service: 10 MB

These defaults are enforced at the gateway and may be tuned per environment. Keep them aligned with backend expectations to avoid 413 Payload Too Large errors.

## 11. Multi-Tenancy

- Tenant resolution via host/path
- Header propagation (X-Tansu-Tenant)
- Tenant-aware caching and routing

Resolution rules

- Subdomain and path are supported:
  - Subdomain form: `<tenant>.yourdomain` (e.g., `acme.apps.example.com`).
  - Path form: `/t/{tenant}` (e.g., `https://apps.example.com/t/acme/...`).
- Precedence: when both are present, the path form takes precedence over subdomain.
- After resolution, the gateway sets the `X-Tansu-Tenant` header for downstream services. Clients do not need to send this header explicitly unless using presigned anonymous flows; in those cases, include `X-Tansu-Tenant` as documented in Storage API.

## 12. Troubleshooting

- Common startup issues
- Certificate and TLS errors
- OIDC discovery and token validation

## 13. Testing & E2E validation

This platform ships with lightweight health checks and end-to-end (E2E) tests that verify core paths through the gateway, identity, and backend services.

### 13.1 Local quick checks

- Health endpoints (all services):
  - Live: `GET /health/live`
  - Ready: `GET /health/ready`
  - Via gateway for each service: `/`, `/identity/`, `/dashboard/`, `/db/`, `/storage/` then append `/health/live` or `/health/ready`.
- Bring services up (developer workflow):
  - VS Code → Run Task… → "dev: up" to build and start services.
  - VS Code → Run Task… → "dev: down" to stop them.
- Dev database (PostgreSQL) recommended for DB features:
  - Use the persistent Citus/Postgres container described earlier, or the helper script at `dev/tools/start-dev-db.ps1`.

### 13.2 Run E2E tests locally

- The E2E test suite lives under `tests/TansuCloud.E2E.Tests` and targets the gateway at `http://localhost:8080` (default dev bind). If you enabled HTTPS on the gateway, adjust the base URL accordingly.
- What is covered today:
  - Health endpoints across services.
  - Identity UI login alias via gateway.
  - Token-based, idempotent tenant provisioning to Database via gateway.
- How to run:
  - Ensure services are up (see 13.1) and that a local PostgreSQL is reachable at `localhost:5432` (the default dev setup).
  - In VS Code, Run Task… → "Run all E2E tests"; or run tests from your IDE/test explorer.
  - Tip: you can run focused suites via provided VS Code tasks (e.g., "Run health E2E tests").
- Notes:
	- Tests accept development HTTPS certificates; no extra trust steps needed for local runs.
	- The provisioning test obtains an access token using the dashboard client (scopes: `db.write admin.full`) and calls the Database provisioning API twice, asserting idempotency.
	- Playwright browsers: to avoid long installs during test runs, preinstall browsers once:
		- Option A (recommended): run `pwsh -NoProfile -File tests/TansuCloud.E2E.Tests/playwright.ps1` once; the script is idempotent and skips if already installed.
		- Option B: set `PLAYWRIGHT_SKIP_INSTALL=1` to skip installs in environments where browsers are pre-baked (e.g., CI agents).

### 13.2.1 Redis-dependent outbox test gating

Some outbox E2E validation requires a real Redis instance (publishing and subscription). These tests are decorated with a custom attribute `RedisFactAttribute` and will be reported as Skipped unless the environment variable `REDIS_URL` is set.

To enable the Redis E2E outbox test locally:

1. Start (or ensure) a Redis container/service is running and reachable.
2. Export `REDIS_URL` before running tests:

```powershell
$env:REDIS_URL = "localhost:6379" # or full configuration string supported by StackExchange.Redis
dotnet test .\tests\TansuCloud.E2E.Tests\TansuCloud.E2E.Tests.csproj -c Debug --filter Full_Dispatcher_Redis_Publish
```

Example skip output when not configured:

```
Full dispatcher loop publishes to Redis and marks dispatched (E2E) [SKIP]
	REDIS_URL not set; Redis-dependent test skipped
```

Rationale:
- Keeps CI fast and deterministic when Redis isn’t provisioned.
- Avoids false negatives due to missing ephemeral infrastructure.
- Local developers can opt-in for the extra signal when modifying outbox/Redis code paths.

If you routinely run with Redis, consider adding a VS Code test task that sets `REDIS_URL` inline so the attribute no longer skips the test.

### 8.2 Metrics dashboard (Prometheus)

The Dashboard exposes an admin-only Metrics page under `/dashboard/admin/metrics`. It renders native charts by proxying queries to Prometheus from the backend service (Prometheus is never accessed directly by the browser).

Key points

- Internal-only: The Dashboard backend calls Prometheus at an internal URL. In Docker Compose, the default is the Prometheus service at `http://prometheus:9090`. If you wire the OpenTelemetry Collector’s Prometheus exporter instead, use `http://otel-collector:8889`. The browser never receives PromQL or Prometheus URLs.
- Allowlist: Only predefined charts/queries are allowed. Arbitrary PromQL from the UI is rejected.
- Tenant scoping: When a tenant is selected or implied via gateway header `X-Tansu-Tenant`, the backend injects label filters (e.g., `tenant="{id}"`) and ignores cross-tenant overrides for non-admin users. Admins may override tenant for cross-tenant views when the header is not set.
- Rate limiting and caching: The backend clamps time ranges and steps and applies a small in-memory cache (~10s) to reduce load.

Available charts (initial set)

- Overview
	- Requests per second by service
	- Error rate (4xx/5xx) by service
	- Latency p95 by service
- Storage
	- Ingress bytes/sec by tenant
	- Egress bytes/sec by tenant
	- Responses by status (2xx/4xx/5xx)
	- Latency p95 by operation
	- Cache hit ratio (by service/operation)
- Database
	- Outbox dispatched/retried/deadlettered rate (aggregated)
- Gateway
  - Proxy requests per second by route
  - Status distribution (2xx/4xx/5xx)
  - Latency p95 by route

Metric sources and names

- Storage service
  - Requests: tansu_storage_requests_total (labels include service, op, tenant).
  - Responses: tansu_storage_responses_total (labels include status, op, tenant).
  - Latency histogram: tansu_storage_request_duration_ms_milliseconds_bucket
    - Note: the OpenTelemetry Prometheus exporter appends the unit to histogram names (…_milliseconds_bucket/_count/_sum). Charts compute p95 via histogram_quantile over buckets.
  - Cache hit ratio: tansu_storage_cache_attempts_total and tansu_storage_cache_hits_total.
  - Tenant scoping: yes (tenant label is injected when selected/implied).
- Database service (Outbox)
  - Counters: outbox_dispatched_total, outbox_retried_total, outbox_deadlettered_total.
  - Origin: Meter "TansuCloud.Database.Outbox"; series are aggregated across labels.
  - Tenant scoping: no (metrics are global; no tenant label).
- Gateway service (reverse proxy)
  - Requests: tansu_gateway_proxy_requests_total (labels include route, status).
  - Latency histogram: tansu_gateway_proxy_request_duration_ms_milliseconds_bucket (labels include route, status, le).
  - Tenant scoping: no (gateway charts ignore tenant filter).
- Prometheus endpoint used by the Dashboard backend (Compose default): `http://prometheus:9090` (or `http://otel-collector:8889` if using the collector exporter)

Troubleshooting

- Empty charts: Ensure Prometheus (or the OTEL Collector exporter) is reachable from the Dashboard container. In Compose, exec into the Dashboard and curl `http://prometheus:9090/-/ready`. Also make sure there is traffic during the selected time window (e.g., call `/storage/health/ready` repeatedly through the gateway).
- Permission denied or missing data: Confirm you’re signed in as an admin for cross-tenant views. Non-admins are restricted to the tenant implied by the gateway.
- NaN/Infinity: The UI guards most divisions by zero; widen the time range or generate load so rates/histograms have samples.

Configuration

- Prometheus base URL, timeouts, default ranges, and caps are configured in the Dashboard via `PrometheusOptions` (appsettings/environment). In Docker Compose, the default is `http://prometheus:9090`; alternatively, use the OTEL collector exporter at `http://otel-collector:8889`.

Quick dev smoke

1) Bring up Compose infra and apps (VS Code tasks: "compose: up infra (pg + redis + pgcat)" then "compose: up apps").
2) Generate some traffic via the gateway, e.g., hit `/storage/health/ready` and `/db/health/ready` a few dozen times.
3) Visit `/dashboard/admin/metrics`, sign in (dev creds in this guide), and select Storage HTTP RPS or Gateway RPS by route; you should see non-zero series and sparklines.

### 13.6 Storage API v1 quick reference

Base path via gateway: `/storage/api`. All requests must include the tenant header `X-Tansu-Tenant: <tenant-id>`. Auth scopes: `storage.read` for reads, `storage.write` for writes. In Development, `admin.full` implies both.

Buckets

- `GET /buckets` — list buckets for the tenant.
- `PUT /buckets/{bucket}` — create a bucket (idempotent).
- `DELETE /buckets/{bucket}` — delete an empty bucket; returns 409 if not empty.

Objects

- `PUT /objects/{bucket}/{key}` — upload an object. Returns 201 Created with a weak `ETag` header.
- `GET /objects/{bucket}/{key}` — download an object. Supports range requests (`Range: bytes=...`) returning 206 and `Content-Range`.
- `HEAD /objects/{bucket}/{key}` — metadata only; returns `ETag`, `Content-Type`, and `Content-Length`.
- `DELETE /objects/{bucket}/{key}` — delete an object.
- `GET /objects?bucket={bucket}&prefix={prefix?}` — list objects in a bucket with optional prefix; items include `Key`, `ETag`, `Length`, `ContentType`, `LastModified`.

Conditional requests

- Lists and items return weak `ETag`s. Send `If-None-Match` on GET to receive `304 Not Modified` when unchanged.
- Send `If-Match` on modifying requests when you need optimistic concurrency; `412 Precondition Failed` on mismatch.

Presigned URLs

- `POST /presign` — generate a temporary signed URL for anonymous access.
  - Body (example):
    - `{"Method":"PUT","Bucket":"bkt","Key":"path/file.txt","ExpirySeconds":300,"MaxBytes":2000000,"ContentType":"text/plain"}`
  - Response: `{ "url": "/storage/api/objects/bkt/path/file.txt?exp=...&sig=...&ct=...&max=...", "expires": 1700000000 }`
  - Enforcement at upload time:
    - `exp` strictly enforced: expired presigned URLs return 403 Forbidden (no clock skew allowance).
    - `max` limits the request `Content-Length`.
    - `ct` enforces Content-Type by media type only (parameters like `charset` are ignored). For example, presigned as `text/plain` accepts uploads with `text/plain; charset=utf-8`.
  - Anonymous client must still include tenant header: `X-Tansu-Tenant`.

Transforms (optional)

- Presign transform URL:
  - `POST /presign/transform` — generate a temporary signed URL for an image transform.
  - Body (example):
    - `{ "Bucket":"bkt","Key":"img/cat.png","Width":800,"Height":0,"Format":"webp","Quality":80,"ExpirySeconds":300 }`
  - Response: `{ "url": "/storage/api/transform/bkt/img/cat.png?w=800&h=0&fmt=webp&q=80&exp=...&sig=...", "expires": 1700000000 }`
- Perform transform:
  - `GET /transform/{bucket}/{key}?w=&h=&fmt=&q=&exp=&sig=`
  - Allowed formats: `webp`, `jpeg`, `png`.
  - Limits and timeouts are enforced (max width/height/total pixels; execution timeout). Requests exceeding limits return 400; expired or invalid signatures return 403.
  - Caching: per-tenant transform cache is keyed by `tenant|bucket|key|sourceETag|fmt|w|h|q`; cache is invalidated automatically when the source object’s ETag changes.
  - ETag: responses reuse the source object’s ETag; `Vary: Accept-Encoding` is set. Content-Type reflects the encoded format.

Response compression

- When clients send `Accept-Encoding: br`, compressible GET responses are served with `Content-Encoding: br` (Brotli). The cache varies by encoding via `Vary: Accept-Encoding`.
- Already-compressed media (e.g., jpg, png, zip, mp4) are not recompressed.

Multipart uploads

- `POST /multipart/{bucket}/initiate/{key}` — returns `{ uploadId }`.
- `PUT /multipart/{bucket}/parts/{partNumber}/{key}?uploadId=...` — upload a part; presign is supported.
- `POST /multipart/{bucket}/complete/{key}?uploadId=...` + body `{ "Parts": [1,2,...] }` — assemble parts into the final object.
- `DELETE /multipart/{bucket}/abort/{key}?uploadId=...` — abort and cleanup.
- Minimum part size is enforced at Complete: all parts except the last must be at least the configured minimum.
- Optional per-part size cap: when `Storage__MultipartMaxPartSizeBytes` > 0, each uploaded part (including the last) must be ≤ that size. Oversized parts are rejected with `413 Payload Too Large` during `PUT /multipart/.../parts/...` and will cause `Complete` to fail validation if somehow bypassed.

Configuration keys (storage service)

- `Storage__RootPath`: Filesystem path for object data (default `/data` inside the container).
- `Storage__PresignSecret`: HMAC secret used to sign presigned URLs.
- `Storage__MultipartMaxPartSizeBytes`: Per-part size cap in bytes for multipart uploads. Use `0` to disable the cap. In development compose, it's set to `1048576` (1 MiB) to exercise E2E coverage.
- Compression options (Brotli): configure under `Storage:Compression` (env prefix `Storage__Compression__*`). Common keys include enabling for HTTP/HTTPS, Brotli level, and MIME allowlist.
- Transform options: configure under `Storage:Transforms` (env prefix `Storage__Transforms__*`), including allowed formats, max width/height/total pixels, default quality, timeout, and cache TTL.

Usage and quotas

- `GET /usage` — returns tenant usage: `{ totalBytes, objectCount, maxTotalBytes?, maxObjectCount?, maxObjectSizeBytes? }`.
- Quotas apply to regular and presigned uploads; violations return RFC7807 ProblemDetails with a descriptive reason.

Admin Dashboard

- The Dashboard includes an admin page at `/admin/storage` that surfaces:
  - Tenant usage header
  - Bucket list/create/delete
  - Object list by prefix (Key, ETag, Length, Content-Type, Last-Modified) and per-object delete
  - Presigned anonymous upload flow with content-type and max-bytes controls
  - HEAD metadata viewer for ETag/Content-Type/Length

Notes

- Always include `X-Tansu-Tenant` on requests through the gateway, including anonymous presigned calls.
- ETags are weak and stable per object content; they enable efficient conditional requests and caching through the gateway.
- Keys in routes may be URL-encoded by clients; the Storage service normalizes keys by unescaping percent-encoding before presign validation. Presign canonicalization uses the unescaped key to avoid signature mismatches for keys with encoded slashes or spaces.

### 13.7 Tenant provisioning API (quick reference)

Base path via gateway: `/db/api`. This API provisions a tenant database, applies migrations, and seeds initial roles/config.

- `POST /provisioning/tenants` — idempotent provisioning call.
  - Body example:
    - `{ "tenantId": "acme", "displayName": "Acme, Inc." }`
  - Auth (production): requires a privileged token. Recommended scopes: `admin.full` or a dedicated provisioning role with `db.write` authority per your policies.
  - Dev bypass (local/E2E only): you may set header `X-Provision-Key: letmein` to bypass auth for quick testing.
  - Idempotency: subsequent calls with the same `tenantId` succeed without duplicating work.
  - Response: HTTP 200/201 with a minimal status payload; failures return RFC7807 ProblemDetails with diagnostics.

### 13.5 Database API v1 quick reference

Base path via gateway: `/db/api` (tenant required via `X-Tansu-Tenant` header). Auth scopes: `db.read` for reads, `db.write` for writes (in Development, `admin.full` implies both).

- Collections
	- `GET /collections` — list with pagination; supports weak ETag on the collection set.
	- `GET /collections/{id}` — get by id; weak ETag; `If-None-Match` → 304.
	- `POST /collections` — create.
	- `PUT /collections/{id}` — update; `If-Match` required for conditional update; 412 on mismatch.
	- `DELETE /collections/{id}` — delete; `If-Match` supported; 412 on mismatch.

- Documents
	- `GET /documents` — list with filters/sort and pagination.
		- Query: `collectionId` (Guid?), `createdAfter`|`createdBefore` (RFC3339), `sortBy` in `id|collectionId|createdAt`, `sortDir` in `asc|desc`, `page` (>=1), `pageSize` (1..500).
		- Weak ETag on the result; `If-None-Match` → 304.
	- `GET /documents/{id}` — get by id; weak ETag; `If-None-Match` → 304.
	- `POST /documents` — create; body includes `collectionId`, optional `embedding` (float[1536]) and `content` (JSON object). JSON payloads are stored as `jsonb`.
	- `PUT /documents/{id}` — update; supports `If-Match`; 412 on mismatch.
	- `DELETE /documents/{id}` — delete; supports `If-Match`; 412 on mismatch.

- Vector search (pgvector)
	- `POST /documents/search/vector` — KNN within a collection. Body: `collectionId` (Guid), `embedding` (float[1536]), `limit` (default 10).
	- `POST /documents/search/vector-global` — ANN across collections with a two-step per-collection cap.
	- Indexing: HNSW indexes are created by migrations when `vector` extension is available; otherwise sequential scan is used.

ETags and conditional requests
- Lists and items return weak ETags. If the ETag you send in `If-None-Match` matches, you’ll get `304 Not Modified`.
- `PUT`/`DELETE` accept `If-Match`; if it doesn’t match the current ETag, you’ll get `412 Precondition Failed`.

Development diagnostics
- During development and E2E, the Database service adds `X-Tansu-Db` to responses to surface the normalized tenant database name (e.g., `tansu_tenant_e2e_server_ank`). This header is not intended for production.

### 13.3 CI pipeline (GitHub Actions)

- CI workflow file: `.github/workflows/e2e.yml`.
- What it does:
	- Provisions a PostgreSQL service (localhost:5432) for the Database service.
	- Builds the solution, launches services in the background, waits for the gateway to become ready, then runs the E2E test project.
	- Publishes TRX test results as an artifact.
- When it runs:
	- On pushes and pull requests targeting `master`.

### 13.4 Troubleshooting test failures

- Gateway not ready:
	- Confirm `http://localhost:8080/health/ready` (or your configured HTTPS URL) returns 200. If not, inspect gateway logs and dependent service health endpoints (see 13.1).
- Database provisioning failures:
	- Ensure PostgreSQL is reachable at `localhost:5432` and credentials match dev settings.
	- Verify the `Provisioning` options in `TansuCloud.Database` (AdminConnectionString, extensions) align with your environment.
- Certificate issues:
	- Local tests ignore TLS validation by design. For browser access, trust the dev cert or enable TLS on the gateway as described in section 5.
- Identity/token issues:
	- Check `/.well-known/openid-configuration` via gateway under `/identity` and verify `/identity/connect/token` is reachable.

## 14. ML Management (Preview)

This section introduces optional, non-breaking conventions and a preview admin page to prepare for Task 34 (ML recommendations and predictions). It does not change runtime behavior yet.

Where to access

- Dashboard page: /dashboard/admin/ml (preferred) or /admin/ml if your gateway exposes a root alias.
- Requires admin access to the Dashboard.

Storage model artifact conventions

- Suggested object layout: models/{modelName}/{version}/...
- Tag artifacts with these metadata keys when uploading:
	- x-tansu-model-name — model identifier (e.g., recommender-v1)
	- x-tansu-model-version — semantic version or build/build-id (e.g., 1.0.0)
	- x-tansu-framework — model runtime/format (ml.net, onnx, pytorch)
	- x-tansu-checksum — sha256 of content
	- x-tansu-created-at — ISO 8601 timestamp
	- x-tansu-source — pipeline/job id or URL

Gateway metrics placeholders (for future wiring)

- Metrics defined but not emitted by default:
	- ml_recommendations_served (counter, items)
	- ml_inference_latency_ms (histogram, ms)
	- ml_recommendation_coverage_pct (observable gauge, percent)

What you can do now

- Organize and upload model artifacts using the conventions above so they’re ready for future rollout.
- Preview the admin UI under ML Management to see planned fields (default model/version, framework, coverage target). Saving is disabled until Task 34.

Next steps (when Task 34 starts)

- Enable saving tenant-level defaults and switch-over controls in the Dashboard.
- Expose admin APIs to list/select available models based on tagged artifacts in Storage.
- Wire Gateway metrics and add dashboards/alerts.

## Appendix A: Docker Compose Examples

- Base compose
- Enabling TLS with volumes and env
- Overriding ports and networks

### A.1 Enable TLS on the gateway (dev or prod)

```yaml
services:
	gateway:
		image: tansucloud-gateway
		ports:
			- "80:8080"    # HTTP
			- "443:8443"   # HTTPS (container listens on 8443)
		volumes:
			- ./certs:/certs:ro
		environment:
			- Kestrel__Endpoints__Https__Url=https://0.0.0.0:8443
			- Kestrel__Endpoints__Https__Certificate__Path=/certs/gateway.pfx
			- GATEWAY_CERT_PASSWORD=${GATEWAY_CERT_PASSWORD}
		depends_on:
			identity:
				condition: service_healthy
			dashboard:
				condition: service_healthy
			db:
				condition: service_healthy
			storage:
				condition: service_healthy
```

Place your `gateway.pfx` under `./certs` and set `GATEWAY_CERT_PASSWORD` in your shell or a `.env` file.

## Appendix B: Configuration Keys

- Services:*BaseUrl
- Oidc:Issuer, Oidc:Authority (dashboard)
- OpenTelemetry:Otlp:Endpoint
- Gateway:Cors:AllowedOrigins
- Kestrel:Endpoints:Http/Https (or env: Kestrel__Endpoints__Https__Url, Kestrel__Endpoints__Https__Certificate__Path)

## Appendix C: Useful Endpoints

- / (gateway health text)
- /health/live, /health/ready (all services)
- /identity/.well-known/openid-configuration
- /dashboard (UI)

### Notes

- This guide is a living document. Fill in environment-specific details (DNS, certs, backends) as they are finalized.

## Appendix D: .env example (production-like)

Place this `.env` beside `docker-compose.yml` and adjust values to your environment.

```env
PUBLIC_BASE_URL=https://app.yourdomain.com

DASHBOARD_CLIENT_SECRET=your-strong-secret

POSTGRES_USER=postgres
POSTGRES_PASSWORD=your-db-password
PGCAT_ADMIN_USER=admin
PGCAT_ADMIN_PASSWORD=your-pgcat-password

# If enabling TLS on the gateway with a PFX mounted under ./certs
GATEWAY_CERT_PASSWORD=pfx-password
```

## Redis and Outbox (Database service)

Purpose

- The Outbox pattern ensures reliable event emission: write domain changes and an "outbox event" in the same database transaction. A background worker publishes the event to Redis later.

Local/dev Redis

- Docker Compose includes `redis:latest` with a named volume `tansu-redisdata` and default port 6379.
- The Database service depends on Redis when Outbox is enabled.

Outbox configuration (Database service)

- Outbox is disabled unless a Redis connection is provided.
- Keys (env or appsettings):
	- `Outbox:RedisConnection` (e.g., `redis:6379` in compose)
	- `Outbox:Channel` (default `tansu.outbox`)
	- `Outbox:PollSeconds` (default `2`)
	- `Outbox:BatchSize` (default `100`)
	- `Outbox:MaxAttempts` (default `8`)

Idempotency for write requests

- Clients may send an `Idempotency-Key` header on write operations (e.g., create document). The Database service records the key and will return the original outcome on safe retries.
- Use a strong, unique value per logical operation. Expire/rotate keys as needed on the client side.
	- The key is stored in `outbox_events.idempotency_key` with a partial unique index to prevent duplicates (when not null). The server may retain keys for operational analysis; clients should not reuse keys across unrelated requests.

Operations

- Health: Redis container exposes `PING` in health checks; verify container is healthy before DB starts processing Outbox.
- Observability: Outbox worker logs dispatched, retried, and dead-lettered events. Metrics are exported via OpenTelemetry when configured.
- Failure handling: After max attempts, events transition to a dead-letter state; operators should inspect and decide to replay or ignore.
	- Redis channel: events are published to the configured channel (default `tansu.outbox`) as JSON envelopes including `{ tenant, collectionId?, documentId?, op }`. Consumers should treat the payload as a contract subject to additive changes.
